=======================
For platform developers
=======================

This page describes how to install, configure and use the Python script which takes jobs from the queue server,
submits them to SLURM, and then posts the results back to the queue server on job completion.


Installation
============

Clone the Git repository::

    $ git clone https://github.com/HumanBrainProject/hbp-neuromorphic-client


Install the requirements and the Python package. We strongly recommend using virtualenv or Anaconda.

::

    $ cd nmpi/nmpi_client
    $ pip install -r requirements.txt
    $ python setup.py install

This installs the `nmpi` Python package and puts an executable script, :file:`nmpi_run.py` with its configuration :file:`saga.cfg`, in the :file:`bin` directory of your virtualenv.


Configuration
=============

The script :file:`nmpi_run.py` uses the nmpi Python client to the api to retrieve the next nmpi job from the queue, it reads the content of the job, creates a folder for it. From the job description, it tries to treat it as a git repository. If it does not work it creates an executable file. Additionally, it retrieves eventual input data.

Then the script performs the simulation in a protected environment. It submits the job to an underlying job queueing system and waits for the answer, and updates the log and status of the job. 

Finally, the script zips the whole nmpi job folder and adds it to the list of job output_data.

The script needs a set of strings to be configured in order to execute the steps above. The companion configuration file :file:`saga.cfg` contains all of them. In principle it should not be necessary to edit the script :file:`nmpi_run.py`.

All values in the configuration script are supplied as *KEY=value* pairs that will be read at the beginning of the saga script.

As for all the interaction with the API, a username and password have to be specified:

.. code-block:: python

    # User
    AUTH_USER=<username>
    AUTH_PASS=<password>

The address of the remote NMPI job server is then specified:

.. code-block:: python

    # NPI addresses
    NMPI_HOST=https://nmpi.hbpneuromorphic.eu
    NMPI_API=/api/v2/

and the identifier for your platform:

.. code-block:: python

    # Identifier for your platform (e.g. "BrainScaleS")
    PLATFORM_NAME=my_platform

together with local directories used for storing the code during execution and for the results:

.. code-block:: python

    # Directory into which Python code will be downloaded/cloned
    WORKING_DIRECTORY=/home/hbp/nmpi

    # Directory into which data files will be written
    DATA_DIRECTORY=/home/hbp/nmpi

Then the executable that will be actually invoked by the queueing system is given, with all the additional parameters.

.. code-block:: python

    # location of the executable that will be called for all scripts:
    JOB_EXECUTABLE=/usr/bin/python

    # Name of the PyNN backend to use (will be appended to the command line)
    DEFAULT_PYNN_BACKEND=nest

    # SLURM partition to use
    JOB_QUEUE=intel

    # 'local' adaptor represents the local machine
    JOB_SERVICE_ADAPTOR=slurm://localhost

These last set of variables is suited for basic interaction and will be probably extended to cope with additional needs.


Running the SAGA script
=======================

You will probably wish to run the script, :file:`nmpi_run.py`, manually during testing, but it is intended to be
launched periodically using cron in production.


Configuring cron
================

We should enable the cron daemon to call our saga script.

In the /etc directory there are probably already sub directories called 'cron.hourly', 'cron.daily', 'cron.weekly' and 'cron.monthly' but probably these solutions are not the one fitting the needs of a job queueing system. 

We can edit a crontab, starting from the one in /etc/crontab. For example, to call the :file:`nmpi_run.py` every five minutes::

    # min hour mday month wday command
    */5 * * * * /path/to/nmpi_run.py
  
